{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DetailsFromFace.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-iqq2b17otu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploadedFile = files.upload() # UPLOADING FILES TO COLAB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgfQrwVm8pF-",
        "colab_type": "code",
        "outputId": "a36e9b77-dadb-418d-ec0d-0d00d072167b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import urllib.request\n",
        "import io\n",
        "import os,sys\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from sklearn.utils import shuffle\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "import dlib\n",
        "import random\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqWtlaTpC4v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PROCESSING JSON\n",
        "\n",
        "data = pd.read_json('Face_Recognition.json',lines = True) # STORE CONTENT OF JSON FILE IN \"DATA\"\n",
        "\n",
        "features = []\n",
        "tempNP = []\n",
        "for num in range(len(data)):                                 # ITERATE THROUGH DATA IN JSON AND STORE THEM IN LIST\n",
        "  URL = data[\"content\"][num]\n",
        "  with urllib.request.urlopen(URL) as url:\n",
        "    f = io.BytesIO(url.read())\n",
        "  pil_image = Image.open(f).convert('RGB')\n",
        "  frame = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
        "  for i in data['annotation'][num]:\n",
        "    if ( len(i['label']) < 4 or i['label'][0] == 'Not_Face' ):\n",
        "      continue\n",
        "    if \"Age\" in i['label'][0]:\n",
        "      age = i['label'][0].split('Age_')[1].strip()\n",
        "      emotion = i['label'][1].split('_')[1].strip()\n",
        "    else:      \n",
        "      emotion = i['label'][0].split('_')[1].strip()\n",
        "      age = i['label'][1].split('Age_')[1].strip()\n",
        "    ethnicity = i['label'][2].split('_')[1].strip()\n",
        "    gender = i['label'][3].split('_')[1].strip()\n",
        "    startX = int(round(i['points'][0]['x'] * i['imageWidth']))\n",
        "    startY = int(round(i['points'][0]['y'] * i['imageHeight']))\n",
        "    endX = int(round(i['points'][1]['x'] * i['imageWidth']))\n",
        "    endY = int(round(i['points'][1]['y'] * i['imageHeight']))\n",
        "    roi = frame[startY:endY,startX:endX]                            # CUTTING THE FACES FROM COMPLETE PICTURE\n",
        "    npImage = np.array(roi,'float32')         \n",
        "    npImage /= 255\n",
        "    npImage = cv2.resize(npImage,(48,48))\n",
        "    tempNP.append(npImage)\n",
        "    values = [emotion,age,ethnicity,gender]\n",
        "    features.append(values)\n",
        "\n",
        "\n",
        "images = np.array(tempNP) # CONVERT THE LIST TO NUMPY ARRAY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CCqelL2GXrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = np.array(features)             # CONVERT FEATURES LIST TO NUMPY ARRAY\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHb56Bf5Mmh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "labels = mlb.fit_transform(features)            # ONE HOT ENCODING IS DONE ON FEATURES ARRAY (Eg: Happy 20-30 below20 .....)\n",
        "                                                #                                                   1     1      0     ......"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doirdDnpGC4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = shuffle(images,labels,random_state=2)        # SHUFFLE THE DATA\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, random_state=42, test_size=0.1)     # splitting for training and testing."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTkeJ2RI6Tg",
        "colab_type": "code",
        "outputId": "775880f4-f6f6-4ada-bd58-947d32f40954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(48,48,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(1, 1), activation='relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(19, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-907dab2c25cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_aArzqNqmkA",
        "colab_type": "code",
        "outputId": "6bdc58cb-92be-45d1-9762-4621abd0772e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=20, batch_size=2)      #epoch = number of iterations"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 178 samples, validate on 20 samples\n",
            "Epoch 1/20\n",
            "178/178 [==============================] - 7s 41ms/step - loss: 0.4365 - acc: 0.7809 - val_loss: 0.3869 - val_acc: 0.8105\n",
            "Epoch 2/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3999 - acc: 0.8066 - val_loss: 0.3714 - val_acc: 0.8000\n",
            "Epoch 3/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3927 - acc: 0.8007 - val_loss: 0.3909 - val_acc: 0.7895\n",
            "Epoch 4/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3920 - acc: 0.8060 - val_loss: 0.3785 - val_acc: 0.8000\n",
            "Epoch 5/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3881 - acc: 0.8019 - val_loss: 0.3839 - val_acc: 0.8026\n",
            "Epoch 6/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3880 - acc: 0.8087 - val_loss: 0.3747 - val_acc: 0.8000\n",
            "Epoch 7/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3848 - acc: 0.8031 - val_loss: 0.3764 - val_acc: 0.8132\n",
            "Epoch 8/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3853 - acc: 0.8034 - val_loss: 0.3745 - val_acc: 0.8000\n",
            "Epoch 9/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3824 - acc: 0.8057 - val_loss: 0.3742 - val_acc: 0.7868\n",
            "Epoch 10/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3824 - acc: 0.8063 - val_loss: 0.3853 - val_acc: 0.7974\n",
            "Epoch 11/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3793 - acc: 0.8090 - val_loss: 0.3794 - val_acc: 0.8105\n",
            "Epoch 12/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3783 - acc: 0.8087 - val_loss: 0.3746 - val_acc: 0.8000\n",
            "Epoch 13/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3790 - acc: 0.8072 - val_loss: 0.3739 - val_acc: 0.8132\n",
            "Epoch 14/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3788 - acc: 0.8202 - val_loss: 0.3716 - val_acc: 0.8184\n",
            "Epoch 15/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3716 - acc: 0.8167 - val_loss: 0.3769 - val_acc: 0.8132\n",
            "Epoch 16/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3703 - acc: 0.8140 - val_loss: 0.3918 - val_acc: 0.8026\n",
            "Epoch 17/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3683 - acc: 0.8229 - val_loss: 0.3858 - val_acc: 0.8026\n",
            "Epoch 18/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3617 - acc: 0.8235 - val_loss: 0.3947 - val_acc: 0.7868\n",
            "Epoch 19/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3534 - acc: 0.8288 - val_loss: 0.4035 - val_acc: 0.7895\n",
            "Epoch 20/20\n",
            "178/178 [==============================] - 0s 3ms/step - loss: 0.3470 - acc: 0.8362 - val_loss: 0.4223 - val_acc: 0.7868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f240150f908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1vLOYJBpFfl",
        "colab_type": "code",
        "outputId": "d895174f-ecb6-4c66-aba3-36edb12c8b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "image = cv2.imread('example.jpeg') # testing input image\n",
        "\n",
        "if image is None:\n",
        "    print(\"Could not read input image\")\n",
        "    exit()\n",
        "\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat') # pretrained model for human face detection\n",
        "\n",
        "faces_cnn = cnn_face_detector(image, 1)\n",
        "\n",
        "for face in faces_cnn: # get bounding box coordinates\n",
        "    x = face.rect.left()\n",
        "    x = int(x - (0.1 * x))\n",
        "    y = face.rect.top()\n",
        "    y = int(y - (0.15 * y))\n",
        "    x2 = face.rect.right()\n",
        "    x2 = int(x2 + (0.1 * x2))\n",
        "    y2 = face.rect.bottom()\n",
        "    y2 = int(y2 + (0.1 * y2))\n",
        "\n",
        "    roi = image[y:y2,x:x2] # extract face from complete picture\n",
        "    cv2.imwrite(os.path.join('face'+str(int(random.random()*10))+'.jpg'), roi) # saving the face with \"face<randomnumber>\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not read input image\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b7f8db92189d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mmod_human_face_detector.dat'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pretrained model for human face detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfaces_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces_cnn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# get bounding box coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: dlib.cnn_face_detection_model_v1, imgs: list, upsample_num_times: int=0, batch_size: int=128) -> std::vector<std::vector<dlib::mmod_rect, std::allocator<dlib::mmod_rect> >, std::allocator<std::vector<dlib::mmod_rect, std::allocator<dlib::mmod_rect> > > >\n    2. (self: dlib.cnn_face_detection_model_v1, img: array, upsample_num_times: int=0) -> std::vector<dlib::mmod_rect, std::allocator<dlib::mmod_rect> >\n\nInvoked with: <dlib.cnn_face_detection_model_v1 object at 0x7f23891bc308>, None, 1\n\nDid you forget to `#include <pybind11/stl.h>`? Or <pybind11/complex.h>,\n<pybind11/functional.h>, <pybind11/chrono.h>, etc. Some automatic\nconversions are optional and require extra headers to be included\nwhen compiling your pybind11 module."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0qqLQcaP2bE",
        "colab_type": "code",
        "outputId": "656c2102-9e27-4be1-c07e-b6b1f5d55531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "files = os.listdir('/content') # getting all files in /content folder of google colab\n",
        "for file in files:\n",
        "  if file[:4] == 'face': # we saved our image of faces with name as \"face<randomnumber>\" \n",
        "    img = cv2.imread(file)\n",
        "    img = np.array(cv2.resize(img,(48,48)),'float32') # cnn accepts only 96x96 image\n",
        "    cv2_imshow(img)\n",
        "    img = img/255 # standardization\n",
        "    \n",
        "    classes = np.array(mlb.classes_) # it contains all the labels of our class\n",
        "    proba = model.predict(img.reshape(1,48,48,3)) # prediction takes place here\n",
        "    top_3 = np.argsort(proba[0])[:-5:-1] \n",
        "    for i in range(4):\n",
        "      print(classes[top_3[i]],proba[0][top_3[i]]*100) # display all possibilities with percentage\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAIAAADYYG7QAAAUgElEQVR4nHV4W6ydx3XeWmsu/23f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\nrkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=48x48 at 0x7F7E6030BD68>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Female 80.42693138122559\n",
            "Neutral 70.29515504837036\n",
            "White 60.82105040550232\n",
            "20_30 48.38664531707764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAIAAADYYG7QAAAVdUlEQVR4nAXBeayl530Q4N+7fft3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\nASzO4xmDK9tiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=48x48 at 0x7F7E6A940208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Neutral 99.99656677246094\n",
            "Asian 99.68774318695068\n",
            "below20 94.90188360214233\n",
            "Male 81.43944144248962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS7olWbTRx3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}